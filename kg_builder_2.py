import pandas as pd
import numpy as np
from neo4j import GraphDatabase
import networkx as nx
from node2vec import Node2Vec
from random import shuffle
import traceback
import sys
from random import randint
import os


def connect_to_neo4j(uri="neo4j+s://1f5f8a14.databases.neo4j.io", user="neo4j", password="3xhy4XKQSsSLIT7NI-w9m4Z7Y_WcVnL1hDQkWTMIoMQ"):
    print(f"ğŸŒ Connecting to Neo4j Aura: {uri}", flush=True)
    return GraphDatabase.driver(uri, auth=(user, password))

def parse_csv(file_path):
    df = pd.read_csv(file_path, sep=";", encoding="utf-8-sig")
    df.columns = [col.strip() for col in df.columns]
    df = df.apply(lambda col: col.str.strip() if col.dtypes == 'object' else col)

    numeric_cols = ['Case_No', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Qchat-10-Score']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col].astype(str).str.replace(",", "."), errors='coerce')

    print("âœ… ÎšÎ±Î¸Î±ÏÎ¯ÏƒÏ„Î·ÎºÎ±Î½ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚:", df.columns.tolist(), flush=True)
    return df.dropna()

def create_nodes(tx, df):
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÏŒÎ¼Î²Ï‰Î½ ÎµÏÏ‰Ï„Î®ÏƒÎµÏ‰Î½ ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬Ï‚ (A1-A10)
    for q in [f"A{i}" for i in range(1, 11)]:
        tx.run("MERGE (:BehaviorQuestion {name: $q})", q=q)

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î´Î·Î¼Î¿Î³ÏÎ±Ï†Î¹ÎºÏÎ½ ÎºÏŒÎ¼Î²Ï‰Î½
    for column in ["Sex", "Ethnicity", "Jaundice", "Family_mem_with_ASD"]:
        for val in df[column].dropna().unique():
            tx.run("MERGE (:DemographicAttribute {type: $type, value: $val})", type=column, val=val)

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÏŒÎ¼Î²Ï‰Î½ Ï…Ï€Î¿Î²Î»Î·Î¸Î­Î½Ï„Ï‰Î½ Î±Ï€ÏŒ
    for val in df["Who_completed_the_test"].dropna().unique():
        tx.run("MERGE (:SubmitterType {type: $val})", val=val)

def create_relationships(tx, df):
    # Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± Î¼Î±Î¶Î¹ÎºÎ® ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®
    case_data = []
    answer_data, demo_data, submitter_data = [], [], []

    for _, row in df.iterrows():
        case_id = int(row["Case_No"])
        upload_id = str(case_id)
        case_data.append({"id": case_id, "upload_id": upload_id})

        # Î£Ï‡Î­ÏƒÎµÎ¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ‰Î½ (HAS_ANSWER)
        for q in [f"A{i}" for i in range(1, 11)]:
            answer_data.append({"upload_id": upload_id, "q": q, "val": int(row[q])})

        # Î£Ï‡Î­ÏƒÎµÎ¹Ï‚ Î´Î·Î¼Î¿Î³ÏÎ±Ï†Î¹ÎºÏÎ½ (HAS_DEMOGRAPHIC)
        for col in ["Sex", "Ethnicity", "Jaundice", "Family_mem_with_ASD"]:
            demo_data.append({"upload_id": upload_id, "type": col, "val": row[col]})

        # Î£Ï‡Î­ÏƒÎµÎ¹Ï‚ Ï…Ï€Î¿Î²Î»Î·Î¸Î­Î½Ï„Ï‰Î½ Î±Ï€ÏŒ (SUBMITTED_BY)
        submitter_data.append({"upload_id": upload_id, "val": row["Who_completed_the_test"]})

    # ÎœÎ±Î¶Î¹ÎºÎ® ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® Cases
    tx.run("""
        UNWIND $data as row 
        MERGE (c:Case {id: row.id}) 
        SET c.upload_id = row.upload_id, c.embedding = null
    """, data=case_data)

    # ÎœÎ±Î¶Î¹ÎºÎ® ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® HAS_ANSWER ÏƒÏ‡Î­ÏƒÎµÏ‰Î½
    tx.run("""
        UNWIND $data as row
        MATCH (q:BehaviorQuestion {name: row.q})
        MATCH (c:Case {upload_id: row.upload_id})
        MERGE (c)-[:HAS_ANSWER {value: row.val}]->(q)
    """, data=answer_data)

    # ÎœÎ±Î¶Î¹ÎºÎ® ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® HAS_DEMOGRAPHIC ÏƒÏ‡Î­ÏƒÎµÏ‰Î½
    tx.run("""
        UNWIND $data as row
        MATCH (d:DemographicAttribute {type: row.type, value: row.val})
        MATCH (c:Case {upload_id: row.upload_id})
        MERGE (c)-[:HAS_DEMOGRAPHIC]->(d)
    """, data=demo_data)

    # ÎœÎ±Î¶Î¹ÎºÎ® ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® SUBMITTED_BY ÏƒÏ‡Î­ÏƒÎµÏ‰Î½
    tx.run("""
        UNWIND $data as row
        MATCH (s:SubmitterType {type: row.val})
        MATCH (c:Case {upload_id: row.upload_id})
        MERGE (c)-[:SUBMITTED_BY]->(s)
    """, data=submitter_data)

def create_similarity_relationships(tx, df, max_pairs=10000):
    pairs = set()
    
    # 1. Î£Ï…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¹ÎºÎ® Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î± (A1-A10)
    for i, row1 in df.iterrows():
        for j, row2 in df.iloc[i+1:].iterrows():
            if sum(row1[f'A{k}'] == row2[f'A{k}'] for k in range(1,11)) >= 7:
                pairs.add((int(row1['Case_No']), int(row2['Case_No'])))

    # 2. Î”Î·Î¼Î¿Î³ÏÎ±Ï†Î¹ÎºÎ® Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±
    demo_cols = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD']
    for col in demo_cols:
        grouped = df.groupby(col)['Case_No'].apply(list)
        for case_list in grouped:
            for i in range(len(case_list)):
                for j in range(i+1, len(case_list)):
                    pairs.add((int(case_list[i]), int(case_list[j])))

    # Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î¿ÏÎ¯Î¿Ï… ÎºÎ±Î¹ Ï„Ï…Ï‡Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·
    pair_list = list(pairs)[:max_pairs]
    shuffle(pair_list)

    # Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ‡Î­ÏƒÎµÏ‰Î½ ÏƒÏ„Î· Neo4j
    tx.run("""
        UNWIND $batch AS pair
        MATCH (c1:Case {id: pair.id1}), (c2:Case {id: pair.id2})
        MERGE (c1)-[:SIMILAR_TO]->(c2)
    """, batch=[{'id1':x, 'id2':y} for x,y in pair_list])

def generate_embeddings(driver):
    temp_folder_path = os.path.join(os.getcwd(), 'node2vec_temp')
    os.makedirs(temp_folder_path, exist_ok=True)
    G = nx.Graph()
    
    print("â³ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ Ï„Î· Neo4j...", flush=True)
    
    # Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ query Ï€Î¿Ï… ÎµÎ³Î³Ï…Î¬Ï„Î±Î¹ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ ÏƒÏ‡Î­ÏƒÎµÏ‰Î½
    with driver.session() as session:
        # Î ÏÏÏ„Î± Ï†Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ ÎºÏŒÎ¼Î²Î¿Ï…Ï‚ Case
        case_nodes = session.run("MATCH (c:Case) RETURN toString(c.id) AS node_id")
        for record in case_nodes:
            G.add_node(record["node_id"])
        
        # ÎˆÏ€ÎµÎ¹Ï„Î± Ï†Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚
        relationships = session.run("""
            MATCH (c:Case)-[r:HAS_ANSWER|HAS_DEMOGRAPHIC|SUBMITTED_BY|SIMILAR_TO]->(n)
            RETURN toString(c.id) AS source, 
                   toString(id(n)) AS target,
                   type(r) AS relationship_type
        """)
        
        rel_count = 0
        for record in relationships:
            source = record["source"]
            target = record["target"]
            if source and target:  # Î‘ÏƒÏ†Î±Î»Î®Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚
                G.add_node(source)
                G.add_node(target)
                G.add_edge(source, target)
                rel_count += 1
        
        print(f"ğŸ“Š Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {rel_count} ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚ Î±Ï€ÏŒ Ï„Î· Î²Î¬ÏƒÎ·", flush=True)
    
    print(f"ğŸ“Š Î¤ÎµÎ»Î¹ÎºÎ¬ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î³ÏÎ¬Ï†Î¿Ï…: {len(G.nodes)} ÎºÏŒÎ¼Î²Î¿Î¹, {len(G.edges)} Î±ÎºÎ¼Î­Ï‚", flush=True)
    
    if len(G.edges) == 0:
        raise ValueError("âŒ ÎŸ Î³ÏÎ¬Ï†Î¿Ï‚ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î±ÎºÎ¼Î­Ï‚! ÎˆÎ»ÎµÎ³Î¾Îµ Ï„Î¹Ï‚ ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î· Neo4j.")
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Node2Vec embeddings
    print("â³ Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î³Î¹Î± Node2Vec...", flush=True)
    node2vec = Node2Vec(
        G,
        dimensions=128,
        walk_length=30,
        num_walks=200,
        workers=4,
        p=1.0,
        q=0.5,
        temp_folder=temp_folder_path
    )

    try:
        print("â³ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...", flush=True)
        model = node2vec.fit(
            window=10,
            min_count=1,
            batch_words=128
        )
        
        print("â³ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· embeddings...", flush=True)
        with driver.session() as session:
            batch = []
            for node_id in G.nodes():
                try:
                    embedding = model.wv[str(node_id)].tolist()
                    batch.append({"node_id": int(node_id), "embedding": embedding})
                    
                    if len(batch) >= 1000:
                        session.run("""
                            UNWIND $batch AS item
                            MATCH (c:Case {id: item.node_id})
                            SET c.embedding = item.embedding
                        """, {"batch": batch})
                        batch = []
                
                except KeyError:
                    print(f"âš ï¸ No embedding for node {node_id}", flush=True)
                    continue
            
            if batch:
                session.run("""
                    UNWIND $batch AS item
                    MATCH (c:Case {id: item.node_id})
                    SET c.embedding = item.embedding
                """, {"batch": batch})

        print(f"âœ… Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ embeddings Î³Î¹Î± {len(G.nodes)} ÎºÏŒÎ¼Î²Î¿Ï…Ï‚", flush=True)
        return True

    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î±: {str(e)}", flush=True)
        traceback.print_exc()
        return False
    finally:
        if os.path.exists(temp_folder_path):
            shutil.rmtree(temp_folder_path)

def build_graph():
    driver = connect_to_neo4j()
    file_path = "https://raw.githubusercontent.com/GiorgosBouh/llm2cypher-asd-app/main/Toddler_Autism_dataset_July_2018_2.csv"

    try:
        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        print("â³ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...", flush=True)
        df = parse_csv(file_path)
        print("ğŸ§  Î”ÎµÎ¯Î³Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:", df.iloc[0].to_dict(), flush=True)

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ¬Ï†Î¿Ï… ÏƒÏ„Î· Neo4j
        with driver.session() as session:
            print("ğŸ§¹ Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€Î±Î»Î¹Î¿Ï Î³ÏÎ¬Ï†Î¿Ï…...", flush=True)
            session.run("MATCH (n) DETACH DELETE n")

            print("â³ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Ï‰Î½ ÎºÏŒÎ¼Î²Ï‰Î½...", flush=True)
            session.execute_write(create_nodes, df)

            print("â³ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î²Î±ÏƒÎ¹ÎºÏÎ½ ÏƒÏ‡Î­ÏƒÎµÏ‰Î½...", flush=True)
            session.execute_write(create_relationships, df)

            print("â³ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ‡Î­ÏƒÎµÏ‰Î½ Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚...", flush=True)
            session.execute_write(create_similarity_relationships, df)

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· embeddings
        print("â³ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± graph embeddings...", flush=True)
        if not generate_embeddings(driver):
            raise RuntimeError("Failed to generate embeddings")

        print("âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ¬Ï†Î¿Ï…!", flush=True)
        sys.exit(0)

    except Exception as e:
        print(f"âŒ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î±: {str(e)}", flush=True)
        traceback.print_exc()
        sys.exit(1)

    finally:
        driver.close()

if __name__ == "__main__":
    build_graph()